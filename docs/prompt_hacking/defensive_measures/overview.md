---
sidebar_position: 0
---

# 🟢 Úvod

Zabránit prompt injekci může být velmi obtížné a existuje proti němu jen málo spolehlivých obranných(@crothers2022machine)(@goodside2021gpt) prostředků. Existuje však několik rozumných řešení. Pokud například vaše aplikace nepotřebuje vypisovat volný text, nepovolujte takové výstupy. Existuje mnoho různých způsobů, jak prompt ochránit. Některé z těch nejčastějších zde probereme.

Tato kapitola se zabývá dalšími strategiemi zdravého rozumu, jako je filtrování slov. Zabývá se také strategiemi vylepšování promptů (obrana instrukcí, postprompting, různé způsoby zapouzdření uživatelského vstupu a značení XML). Nakonec se zabýváme použitím LLM k vyhodnocení výstupu a některými specifičtějšími přístupy k modelům. 
