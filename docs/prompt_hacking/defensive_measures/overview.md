---
sidebar_position: 0
---

# 🟢 Přehled

Zabránit promptnímu injektování může být velmi obtížné a existuje proti němu jen málo spolehlivých obranných(@crothers2022machine)(@goodside2021gpt) prostředků. Existuje však několik rozumných
řešení. Pokud například vaše aplikace nepotřebuje vypisovat volný text, nepovolujte takové výstupy. Existuje mnoho různých způsobů, jak výzvu obhájit. Některé z těch nejčastějších zde probereme.

Tato kapitola se zabývá dalšími strategiemi zdravého rozumu, jako je filtrování slov. Zabývá se také strategiemi vylepšování promptů (obrana instrukcí, postpromptování, různé způsoby zapouzdření uživatelského vstupu a značení XML). Nakonec se zabýváme použitím LLM k vyhodnocení výstupu a některými specifičtějšími přístupy k modelům. 
